#!/bin/bash

### runs pssh2 for a set of md5 sums
#$ -o /dev/null
#$ -e /dev/null

#set -x

seqfile='query.fasta' 
hhblitsLog='hhblits.log' 
a3mfile='query.uniprot20.a3m' 
hmmfile='query.uniprot20.hhm'
hhrfile='query.uniprot20.hhr'
rootDir="/mnt/project/pssh/pssh2_project/" 
temp_work="/tmp/pssh2/"
hhlib=$rootDir'hhsuite-2.0.13'
local_paths=''
dbDate='current'
dbName='pdb_full'
pssh_normal_queue='pssh'
pssh_long_queue='pssh_bigJobs'
pssh_fail_queue='pssh_failed'
storage='EBS'
# change in config file if we desire to use more
n_cpu=1
### base path to cache
pssh2_cache="/mnt/data/pssh_cache/"
### table to store pssh2 calculation status in
status_table="pssh2_active_counts"
### table to store pssh2 calculation results in
table_name="pssh2_active"
### table to store the aws run statistics
aws_table="aws_statistics"


if [ -z "$conf_file" ]; then
	conf_file='/etc/pssh2.conf'
fi


# get configurable options, e.g. local file paths
if [ -s $conf_file ]
then
	source $conf_file
fi


# by default we want to use the system installation
# but if local_paths is set we have the option to change the path and instead use the local variants
if [ $local_paths ]
then
	PATH=$local_paths:$PATH
	export PATH
	echo "Using path: $PATH"
fi



usage()
{
cat << EOT
NAME
  pssh2_aws - generate pssh2 type sequence-to-structrue alignments for many sequences on AWS
SYNOPSIS
  pssh2_aws [-h] [-D] [-- ...]
DESCRIPTION
  pssh2_aws runs until terminated externally.
  It (repeatedly) queries for md5 sums to process,
  for each md5 it
  - gets corresponding cache entries from S3,
  - gets the associated sequences from the database,
  - runs pssh2_seq (which adds the alignment to the database),
  - stores the result files in S3.
  If there are no md5 sums to process, it sleeps for a radom time.
  See pssh2_seq -h for more details on pssh2_seq.
  Defaults are configured in $conf_file.
OPTIONS
  -h          The option -h displays help and exits.
  -D          Debug option: do not remove or zip output files (passed on to pssh2_seq)
  Any other parameters behind "--" are passed on to the child scripts.
AUTHOR
  Andrea Schafferhans <andrea.schafferhans@rostlab.org>
EOT
}



debug=0
passOpt=" " 
while getopts :Dhm: opt
do
	case $opt in
	D) debug=1; passOpt="$passOpt -$opt";; 
	h) usage; echo " "; pssh2_seq -h; exit;;
#	m) md5list=$OPTARG;;
#	*) passOpt="$passOpt $OPTARG";;
	esac
done

if [ $debug -eq 1 ]
then
	set -x
fi

shift $(expr $OPTIND - 1 )
passOpt="$passOpt $@"
get_seq=0

REGION=`wget -q 169.254.169.254/latest/meta-data/placement/availability-zone -O- | sed 's/.$//'`
ACCOUNT=`wget -q 169.254.169.254/latest/dynamic/instance-identity/document -O- | grep accountId | awk -F'"' '{print $4}'`
instance_id=`wget 169.254.169.254/latest/meta-data/instance-id -qO-`
instance_type=`wget 169.254.169.254/latest/meta-data/instance-type -qO-`
availability_zone=`wget 169.254.169.254/latest/meta-data/placement/availability-zone -qO-`	
pid=$BASHPID

cachingRoutine=$rootDir'src/util/copy_to_S3'

if [ !-d $temp_work ]
then
	mkdir -p $temp_work
fi
cd $temp_work

while true 
do

	startTime=$SECONDS
	
	# get the next md5 to process
	# We receive a message (with the next md5 sum) which then gets hidden from other workers for one hour 
    # (so that the md5 is not processed multiple times). 
    # The call to aws is delayed up to 20 seconds (to give AWS infrastructure time to look 
    # for messages in case none is readily available at the query endpoint). 
    # Unused messages (= md5 sums) will be discarded automatically after two weeks 
  	# (when no worker has taken care of them).
	MSG=`aws --region=$REGION sqs receive-message --queue-url https://sqs.$REGION.amazonaws.com/$ACCOUNT/$pssh_normal_queue --query 'Messages[*].[ReceiptHandle,Body]' --output text`
	HANDLE=`awk '{print $1}' <<< $MSG`
	md5=`awk '{print $2}' <<< $MSG`
	keepWorking=0	

	# if we really received something, we process, otherwise we poll again until we are killed
	if [ -z $md5 ]
	then
		keepWorking=0	
	else
		keepWorking=1	
	fi
	
	# make sure we have a cache directory we can work in and get data from the cache
	if [ $keepWorking -eq 1 ]
	then

#		# get subdir names for cache structure
#		M=`echo $md5|cut -b1,2`
#		M2=`echo $md5|cut -b3,4`
#		### full path to cachedir
#		CC="$pssh2_cache$M/$M2/$md5"
#		mkdir -p $CC

		# here, we don't only set the path location, but also fetch the data from the cache
		CC=`$rootDir/src/util/aws_local_cache_handler -m $md5 -r | tail -1`

##   This part is now delegated to aws_local_cache_handler
#		if [ -d $CC ] 
#		then
#			echo "working in $CC"
#			# look for md5 in S3 and unpack
#			if aws --region=$REGION s3 ls s3://aquaria-$ACCOUNT-$REGION/$md5 > /dev/null
#			then
#				cd $CC
#				# gets the data under the tar directly into current directory
#				aws --region=$REGION s3 cp s3://aquaria-$ACCOUNT-$REGION/$md5 - | tar -xz
#				cd $temp_work
#			fi
#			keepWorking=1
#		else 
		if [ ! -d $CC ]
		then
			echo "ERROR: was not able to work on cache for $CC please go fix"
			# LATER: we should probably raise and error and die here (or below?)!
			keepWorking=0
			count=-999
		fi
	fi
	
	# make sure we have an input sequence
	if [ $keepWorking -eq 1 ]
	then
		input_seq_file=$CC/$seqfile

		# check whether an input file already exists in $CC
		if [ -s $input_seq_file ] 
		then
			old_md5=`cat $input_seq_file|fasta_to_md5`
			if  [ $old_md5 == $md5 ]
			then
				echo "working with old file $input_seq_file, with md5: $old_md5"
			else 
				get_seq=1
				echo "old file $input_seq_file, has different md5: $old_md5 -> retrieve again!"
			fi
		else
			get_seq=1
		fi

		if [ $get_seq -eq 1 ]
		then 
			temp_fasta_file=`get_fasta_for_md5 $md5`
			if [ -s $temp_fasta_file ]
			then	
				cp $temp_fasta_file $input_seq_file
			else 
				echo "ERROR: didn't get the sequence for $md5"
			fi
		fi		

		if [ -s $input_seq_file ] 
		then
			keepWorking=1
		else
			keepWorking=0
			count=-99
		fi
	fi

	# prepare the statistics
	maxmem=0
	sysTime=0
	usrTime=0
	wallTime=0
#	prepTime=$SECONDS
	
	# now we have prepared everything, we can actually do the work
	if [ $keepWorking -eq 1 ]
	then
		cd $CC
#		pwd
#		ls -lahtr
		stderr=$((( command time -f ' MemTimeSUe_Stat %M %S %U %e' pssh2_seq $passOpt; ) 1>/dev/null; ) 2>&1; )
		statistics=`echo $stderr | sed 's/.* MemTimeSUe_Stat \([ 0-9.]*\)$/\1/'`
		maxmem=`echo $statistics| awk '{print $1}'`
		sysTime=`echo $statistics| awk '{print $2}'`
		usrTime=`echo $statistics| awk '{print $3}'`
		wallTime=`echo $statistics| awk '{print $4}'`
		
#		pssh2_seq $passOpt
		# evaluate return state of pssh2_seq for messaging the queue? 
		count=`DB.pssh2_local "select * from $status_table where md5=\"$md5\"" | tail -n +2 | cut -f 2`
		# if for some reason pssh2_execution failed then count should be '', so we can detect that later
			
		# pack directory and write to S3
#		tar -cz * | aws --region=$REGION s3 cp - s3://aquaria-$ACCOUNT-$REGION/$md5
#		tar -c /mnt/data/pssh2_cache/`sed 's/\(..\).*/\1/'<<<$MD5`/`sed 's/..\(..\).*/\1/'<<<$MD5`/$MD5 | aws --region=$REGION s3 cp - s3://aquaria-$ACCOUNT-$REGION/$MD5

		$rootDir/src/util/aws_local_cache_handler -m $md5 -s
		cd $temp_work
		if [ $debug -eq 1 ]
		then
			echo "keeping $CC for debugging"
		else
			rm -r $CC
		fi
		
		finishTime=$SECONDS
		runtime=$(($finishTime-$startTime))
		
		# write out statistics
		jsonFile=$temp_work$md5.json
		cat << EOF > $jsonFile
{
	"sequence_md5": {"S": "$md5"},
	"conditionString": {"S": "$instance_type-$storage-$n_cpu"},
	"architecture": {"S": "$instance_type"},
	"storage": {"S": "$storage"},
	"nCpu": {"N": "$n_cpu"},
	"maxmem": {"N": "$maxmem"},
	"sysTime": {"N": "$sysTime"},
	"usrTime": {"N": "$usrTime"},
	"wallTime": {"N": "$wallTime"},
	"scriptTime": {"N":  "$runtime"},
	"command": {"S": "pssh2_aws"},
	"instanceId":{"S":"$instance_id"}
}
EOF

		aws dynamodb put-item --region=$REGION --table-name "runTimes" --item file://$jsonFile

		
		
	elif [ ! -z $md5 ] 
	then
		# if we didn't do anything but had an md5, 
		# we need to store the info about that failure in the database;
		# here we don't get cases where the execution of pssh2_seq failed; but these should be rare setup problems
		s=`date +%s`
		finishTime=$SECONDS
		runtime=$(($finishTime-$startTime))
		DB.pssh2_local "insert into $status_table set md5=\"$md5\" , count=$count, stamp=$s , runtime=$runtime" 
		echo "ERROR: could not work on sequence: $md5 (error code: $count)"
	fi

#	finishTime=$SECONDS
#	runtime=$(($finishTime-$startTime))
#	s=`date +%s`
#	DB.pssh2_local "insert into $aws_table set md5=\"$md5\", stamp=$s, pid=$pid, maxmem=$maxmem, sysTime=$sysTime, usrTime=$usrTime, wallTime=$wallTime, runTime=$runTime, instance_id=\"$instance_id\", instance_type=\"$instance_type\", availability_zone=\"$availability_zone\"" 
	
	# send the queue a message that this sequence has been processed
	# if the count is -999 the compute node had a problem with the cache
	# if the count is -99 the sequence has a problem
	# if the count is -3 then no structures had been found (no pssh2 file generated)
	# if the count is -2 then scanning structures had failed -> try rerun with more memory
	# if the count is -1 then building the hmm had failed -> try rerun with more memory

	finished=0
	redo_large=0
	# if we didn't have to do anything we cannot notify the queue -> finished is 0
	if [ -z $md5 ]
	then
		finished=0
	elif [ $count -gt -1 ]
	then 
		finished=1
	elif [ $count -eq -1 ]
	then
		redo_large=1
	elif [ $count -eq -2 ]
	then
		redo_large=1
	else
		finished=1
		aws --region=$REGION sqs send-message --queue-url https://sqs.$REGION.amazonaws.com/$ACCOUNT/$pssh_fail_queue --message-body $md5
		# LATER: possibly write some log messages about failures?
	fi
		
	if [ $redo_large -eq 1 ]
	then
# 		submit to another queue before we tell this one we are done?
		aws --region=$REGION sqs send-message --queue-url https://sqs.$REGION.amazonaws.com/$ACCOUNT/$pssh_long_queue --message-body $md5
		finished=1
	fi
	
	if [ $finished -eq 1 ]
	then
		aws --region=$REGION sqs delete-message --queue-url https://sqs.$REGION.amazonaws.com/$ACCOUNT/$pssh_normal_queue --receipt-handle $HANDLE
	fi

	# reset the variables so we don't accidentally use them again
	md5=""
	HANDLE=""
	
done

